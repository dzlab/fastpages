{
  
    
        "post0": {
            "title": "Title",
            "content": "Text classification with BERT using TF Text . Setup . try: # %tensorflow_version only exists in Colab. %tensorflow_version 2.x except Exception: pass . TensorFlow 2.x selected. . Install dependencies . %%capture %%bash pip install -U tensorflow-text . Import modules . import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split import tensorflow as tf import tensorflow_text as text import tensorflow_hub as hub import tensorflow_datasets as tfds from tensorflow.keras.layers import Dense, Dropout, Input from tensorflow.keras.models import Model . Set default options for modules . pd.set_option(&#39;display.max_colwidth&#39;, -1) . GPU check . num_gpus_available = len(tf.config.experimental.list_physical_devices(&#39;GPU&#39;)) print(&quot;Num GPUs Available: &quot;, num_gpus_available) assert num_gpus_available &gt; 0 . Num GPUs Available: 1 . config = { &#39;seed&#39;: 31, &#39;batch_size&#39;: 64, &#39;epochs&#39;: 10, &#39;max_seq_len&#39;: 128 } . Data . Download the pretrained BERT model . BERT_URL = &quot;https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1&quot; bert_layer = hub.KerasLayer(BERT_URL, trainable=False) vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy() do_lower_case = bert_layer.resolved_object.do_lower_case.numpy() print(f&#39;BERT vocab is stored at : {vocab_file}&#39;) print(f&#39;BERT model is case sensitive: {do_lower_case}&#39;) . BERT vocab is stored at : b&#39;/tmp/tfhub_modules/03d6fb3ce1605ad9e5e9ed5346b2fb9623ef4d3d/assets/vocab.txt&#39; BERT model is case sensitive: True . Load the vocab file that corresponds to the pretrained BERT . def load_vocab(vocab_file): &quot;&quot;&quot;Load a vocabulary file into a list.&quot;&quot;&quot; vocab = [] with tf.io.gfile.GFile(vocab_file, &quot;r&quot;) as reader: while True: token = reader.readline() if not token: break token = token.strip() vocab.append(token) return vocab vocab = load_vocab(vocab_file) . Use BERT vocab to create a word to index lookup table . def create_vocab_table(vocab, num_oov=1): &quot;&quot;&quot;Create a lookup table for a vocabulary&quot;&quot;&quot; vocab_values = tf.range(tf.size(vocab, out_type=tf.int64), dtype=tf.int64) init = tf.lookup.KeyValueTensorInitializer(keys=vocab, values=vocab_values, key_dtype=tf.string, value_dtype=tf.int64) vocab_table = tf.lookup.StaticVocabularyTable(init, num_oov, lookup_key_dtype=tf.string) return vocab_table vocab_lookup_table = create_vocab_table(vocab) . Use BERT vocab to create a index to word lookup table . def create_index2word(vocab): # Create a lookup table for a index to token vocab_values = tf.range(tf.size(vocab, out_type=tf.int64), dtype=tf.int64) init = tf.lookup.KeyValueTensorInitializer(keys=vocab_values, values=vocab) return tf.lookup.StaticHashTable(initializer=init, default_value=tf.constant(&#39;unk&#39;), name=&quot;index2word&quot;) index2word = create_index2word(vocab) . Check out the indices for the following tokens . vocab_lookup_table.lookup(tf.constant([&#39;[PAD]&#39;, &#39;[UNK]&#39;, &#39;[CLS]&#39;, &#39;[SEP]&#39;, &#39;[MASK]&#39;])) . &lt;tf.Tensor: shape=(5,), dtype=int64, numpy=array([ 0, 100, 101, 102, 103])&gt; . Check out the token corresponding to an index . index2word.lookup(tf.constant([0], dtype=&#39;int64&#39;)).numpy() . [b&#39;[PAD]&#39;] . Create a BERT tokenizer using TF Text . tokenizer = text.BertTokenizer( vocab_lookup_table, token_out_type=tf.int64, lower_case=do_lower_case ) . Lookup for the BERT token IDs for padding and start/end of sentence. . PAD_ID = vocab_lookup_table.lookup(tf.constant(&#39;[PAD]&#39;)) # padding token CLS_ID = vocab_lookup_table.lookup(tf.constant(&#39;[CLS]&#39;)) # class token SEP_ID = vocab_lookup_table.lookup(tf.constant(&#39;[SEP]&#39;)) # sequence separator token . Preprocessing . Define the logic to preprocess data and format it as required by BERT . def preprocess(record): review, label = record[&#39;text&#39;], record[&#39;label&#39;] # process review to calculate BERT input ids, mask, type_ids = preprocess_bert_input(review) return (ids, mask, type_ids), label def preprocess_bert_input(review): # calculate tokens ID ids = tokenize_text(review, config[&#39;max_seq_len&#39;]) # calculate mask mask = tf.cast(ids &gt; 0, tf.int64) mask = tf.reshape(mask, [-1, config[&#39;max_seq_len&#39;]]) # calculate tokens type ID zeros_dims = tf.stack(tf.shape(mask)) type_ids = tf.fill(zeros_dims, 0) type_ids = tf.cast(type_ids, tf.int64) return (ids, mask, type_ids) def tokenize_text(review, seq_len): # convert text into token ids tokens = tokenizer.tokenize(review) # flatten the output ragged tensors tokens = tokens.merge_dims(1, 2)[:, :seq_len] # Add start and end token ids to the id sequence start_tokens = tf.fill([tf.shape(review)[0], 1], CLS_ID) end_tokens = tf.fill([tf.shape(review)[0], 1], SEP_ID) tokens = tokens[:, :seq_len - 2] tokens = tf.concat([start_tokens, tokens, end_tokens], axis=1) # truncate sequences greater than MAX_SEQ_LEN tokens = tokens[:, :seq_len] # pad shorter sequences with the pad token id tokens = tokens.to_tensor(default_value=PAD_ID) pad = seq_len - tf.shape(tokens)[1] tokens = tf.pad(tokens, [[0, 0], [0, pad]], constant_values=PAD_ID) # and finally reshape the word token ids to fit the output # data structure of TFT return tf.reshape(tokens, [-1, seq_len]) . Dataset . Download the dataset from TF Hub and process it . train_ds, valid_ds = tfds.load(&#39;imdb_reviews&#39;, split=[&#39;train&#39;, &#39;test&#39;], shuffle_files=True) train_ds = train_ds.shuffle(1024).batch(config[&#39;batch_size&#39;]).prefetch(tf.data.experimental.AUTOTUNE) valid_ds = valid_ds.shuffle(1024).batch(config[&#39;batch_size&#39;]).prefetch(tf.data.experimental.AUTOTUNE) train_ds, valid_ds = train_ds.map(preprocess), valid_ds.map(preprocess) . Model . input_ids = Input(shape=(config[&#39;max_seq_len&#39;],), dtype=tf.int32, name=&quot;input_ids&quot;) input_mask = Input(shape=(config[&#39;max_seq_len&#39;],), dtype=tf.int32, name=&quot;input_mask&quot;) input_type_ids = Input(shape=(config[&#39;max_seq_len&#39;],), dtype=tf.int32, name=&quot;input_type_ids&quot;) pooled_output, sequence_output = bert_layer([input_ids, input_mask, input_type_ids]) drop_out = Dropout(0.3, name=&quot;dropout&quot;)(pooled_output) output = Dense(1, activation=&#39;sigmoid&#39;, name=&quot;linear&quot;)(drop_out) model = Model(inputs=[input_ids, input_mask, input_type_ids], outputs=output) model.compile(optimizer=&quot;adam&quot;, loss=&quot;binary_crossentropy&quot;, metrics=[&quot;accuracy&quot;]) . model.summary() . Model: &#34;model_1&#34; __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_ids (InputLayer) [(None, 128)] 0 __________________________________________________________________________________________________ input_mask (InputLayer) [(None, 128)] 0 __________________________________________________________________________________________________ input_type_ids (InputLayer) [(None, 128)] 0 __________________________________________________________________________________________________ keras_layer (KerasLayer) [(None, 768), (None, 109482241 input_ids[0][0] input_mask[0][0] input_type_ids[0][0] __________________________________________________________________________________________________ dropout (Dropout) (None, 768) 0 keras_layer[1][0] __________________________________________________________________________________________________ linear (Dense) (None, 1) 769 dropout[0][0] ================================================================================================== Total params: 109,483,010 Trainable params: 769 Non-trainable params: 109,482,241 __________________________________________________________________________________________________ . Training . model.fit(train_ds, validation_data=valid_ds, epochs=config[&#39;epochs&#39;]) . Epoch 1/10 391/391 [==============================] - 499s 1s/step - loss: 0.6654 - accuracy: 0.6016 - val_loss: 0.5977 - val_accuracy: 0.7028 Epoch 2/10 391/391 [==============================] - 510s 1s/step - loss: 0.6063 - accuracy: 0.6712 - val_loss: 0.5650 - val_accuracy: 0.7282 Epoch 3/10 391/391 [==============================] - 510s 1s/step - loss: 0.5839 - accuracy: 0.6969 - val_loss: 0.5494 - val_accuracy: 0.7362 Epoch 4/10 391/391 [==============================] - 511s 1s/step - loss: 0.5730 - accuracy: 0.7025 - val_loss: 0.5388 - val_accuracy: 0.7455 Epoch 5/10 391/391 [==============================] - 510s 1s/step - loss: 0.5696 - accuracy: 0.7058 - val_loss: 0.5376 - val_accuracy: 0.7417 Epoch 6/10 391/391 [==============================] - 510s 1s/step - loss: 0.5613 - accuracy: 0.7146 - val_loss: 0.5268 - val_accuracy: 0.7517 Epoch 7/10 391/391 [==============================] - 510s 1s/step - loss: 0.5608 - accuracy: 0.7130 - val_loss: 0.5233 - val_accuracy: 0.7544 Epoch 8/10 391/391 [==============================] - 510s 1s/step - loss: 0.5625 - accuracy: 0.7106 - val_loss: 0.5217 - val_accuracy: 0.7555 Epoch 9/10 391/391 [==============================] - 510s 1s/step - loss: 0.5603 - accuracy: 0.7125 - val_loss: 0.5199 - val_accuracy: 0.7535 Epoch 10/10 391/391 [==============================] - 510s 1s/step - loss: 0.5567 - accuracy: 0.7159 - val_loss: 0.5150 - val_accuracy: 0.7591 . &lt;tensorflow.python.keras.callbacks.History at 0x7f2fffddba58&gt; . Evaluation . test_text_ds = tfds.load(&#39;imdb_reviews&#39;, split=&#39;unsupervised&#39;, shuffle_files=True) test_ds = test_text_ds.shuffle(1024).batch(config[&#39;batch_size&#39;]).prefetch(tf.data.experimental.AUTOTUNE) test_ds = test_ds.map(preprocess) . Check how test text is tokenized . test_text = [record[&#39;text&#39;].numpy() for record in test_text_ds.take(10)] . ids = tokenize_text(test_text, config[&#39;max_seq_len&#39;]) . tokens = [b&#39; &#39;.join(tokens_array) for tokens_array in index2word.lookup(ids).numpy()] . pd.DataFrame({&#39;tokens&#39;: tokens}) . tokens . 0 b&quot;[CLS] spoil ##er - now knowing the ending i find it so clever that the whole movie takes place in a motel and each character has a different room . even sane people have many different aspects to their personality , but they don &#39; t let them become dominant - - they are controlled . malcolm &#39; s various personalities and needs were person ##ified in each character . the prostitute mother ( amanda pee ##t ) , the part of him who hated her for being a prostitute ( larry ) , the loving mother he wish he had , the loving father he wish he had , the selfish part of himself ( actress ) , the violent part of his personality ( ray [SEP]&quot; | . 1 b&quot;[CLS] i knew about this film long before i saw it . in fact , i had to buy the dvd in order to see it because no video store carried it . i didn &#39; t mind spending the $ 12 to buy it used because i collect off the wall movies . the new limited edition double dvd has great sound and visually not bad . i found myself laughing much more then &lt; br / &gt; &lt; br / &gt; jolt ##ing in fear , although there were a few scenes were i was startled . &lt; br / &gt; &lt; br / &gt; if you enjoy off the wall 70s sci - fi / horror movies , you probably will eat this one [SEP]&quot; | . 2 b&quot;[CLS] this movie is really really awful . it &#39; s as bad as zombie 90 well maybe not that bad but pretty close . if your a fan of the italian horror movies then you might like this movie . i thought that it was dam near un ##watch ##able of course i &#39; m not a fan of the italian movies . the only italian movie that was ok was jungle holocaust . which is one over ##rated movie . this film is way over ##rated . but let &#39; s get started with how horrible this film really is shall we . the acting is goofy and horrible . the effects suck . no plot with this movie . little gore which is the [SEP]&quot; | . 3 b&#39;[CLS] wait a minute . . . yes i do . &lt; br / &gt; &lt; br / &gt; the director of &#39; the breed &#39; has obviously seen terry gill ##iam &#39; s &#39; brazil &#39; a few too many times and asked himself the question , &quot; if &#39; brazil &#39; had been an ill - conceived tale about vampires in the near future , what would it be like ? &quot; well , i &#39; ll tell ya , it &#39; d be like 91 minutes of a swedish whore kicking you in the groin , only not as satisfying . the dialogue was laced with gr ##at ##uit ##ous curse words and tri ##te one - liner ##s , and whoever edited this [SEP]&#39; | . 4 b&quot;[CLS] this is the type of movie that &#39; s just barely involving enough for one viewing , but i don &#39; t think i could stand to watch it again . it looks and plays like a mid - seventies tv movie , only with some gr ##at ##uit ##ous sex and violence thrown in . &lt; br / &gt; &lt; br / &gt; i agree with several previous posters - - her ##ve ville ##chai ##ze is not very menacing , and at times even comes off as un ##int ##ended comedy . at least the other two villains make up for that . also , it was jolt ##ing to see jonathan fr ##id is such a pedestrian role , which definitely under - [SEP]&quot; | . 5 b&quot;[CLS] i like sci - fi movies and everything &#39; bout it and aliens , so i watched this flick . nothing new , nothing special , average acting , typical h . b . davenport &#39; story , weak and che ##es ##y fx &#39; s , bad ending of movie , but still the author idea is good . the marines on lost island find the truth about alien landing there and truth about past - experiments on them . they die one after one , some of them were killed by lonely alien , and others by human enemies . ufo effects , when it flees and crush ##es are bad , too . the voices of angry alien are funny , too . [SEP]&quot; | . 6 b&quot;[CLS] i was lucky enough to see a preview of this film tonight . this was a very cool , eerie film . well acted , especially by ska ##rs ##gard who played his role of terry glass perfectly . sob ##ies ##ki did a very good job too as it seems to me that she has a bright future ahead of her . the music was well placed but was fairly standard . the use of shadows was quite interesting as well . overall , this was quite a nice surprise considering i &#39; m not much a fan of this genre . 7 / 10 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]&quot; | . 7 b&#39;[CLS] my kids and i love this movie ! ! we think that richard pry ##or and the whole cast did a wonderful job in the movie . it means more to us now since the passing of richard ! ! we will miss his sense of humor . but his movies and shows will stay with us forever ! ! we especially love the parts of brad , frank crawford and ar ##lo pear ! ! they had some one liner ##s in the movie that were great ! ! my son and i love to quote those one liner ##s when we see each other and my daughter will join us when we discuss the movie . we thought the moving guys were terrific . [SEP]&#39; | . 8 b&quot;[CLS] somehow the an ##ima ##trix shorts with the most interesting premises have the worst outcome . mat ##ric ##ulated is the worst of the bunch ( although it &#39; s a close call with program ) , as it takes a great idea ( showing the machines the beauty of mankind by plug ##ging them in ) and turns it into the worst experience of the 9 . &lt; br / &gt; &lt; br / &gt; as i said , the story begins promising and interesting , but ends with a long , long , long sequence of &#39; weird &#39; images , a cross between the famous scenes from 2001 and v ##ga - rain ( who can remember it ) , but not as [SEP]&quot; | . 9 b&quot;[CLS] while holiday ##ing in the basque region of spain , two couples discover a child whose hands are severely miss ##ha ##pen . the child has been gravely mist ##reate ##d , and , as a result , cannot communicate . the two couples reluctantly decide to rescue her and report her circumstances to the authorities . however , severe weather and the dense ##ness of the forest surrounding their holiday home make it impossible for them to make a quick get ##away . soon , the local inhabitants become aware that the girl is missing , and they right ##ly suspect the holiday - makers of taking her . suspicions and paranoia begin to fest ##er , and it isn &#39; t long before violence [SEP]&quot; | . Run prediction on test reviews . result = model.predict(test_ds) . result.shape . (50000, 1) . result_df = pd.DataFrame({&#39;label&#39;: tf.squeeze(result[:10]).numpy(), &#39;text&#39;: test_text}) result_df.head() . label text . 0 0.464566 | b&quot;SPOILER - Now knowing the ending I find it so clever that the whole movie takes place in a motel and each character has a different room. Even sane people have many different aspects to their personality, but they don&#39;t let them become dominant -- they are controlled. Malcolm&#39;s various personalities and needs were personified in each character. The prostitute mother (Amanda Peet), the part of him who hated her for being a prostitute (Larry), the loving mother he wish he had, the loving father he wish he had, the selfish part of himself (actress), the violent part of his personality (Ray Liotta and Busey), the irrational emotions he feels and his need to be loved (Ginnie) and his attempts to control those feelings (Lou), the hurt little boy who sees far too many traumatic things in his life, and of course, John Cusack who seems to represent Malcolm himself trying to analyze and understand all the craziness in his mind, tries to follow the rules (accepting responsibility for the car accident), help others (giving Amanda Peet a ride, and stitching up the mother). Very cleverly done!&quot; | . 1 0.252326 | b&#39;I knew about this film long before I saw it. In fact, I had to buy the DVD in order to see it because no video store carried it. I didn &#39;t mind spending the $12 to buy it used because I collect off the wall movies. The new limited edition double DVD has great sound and visually not bad. I found myself laughing much more then&lt;br /&gt;&lt;br /&gt;jolting in fear, although there were a few scenes were I was startled.&lt;br /&gt;&lt;br /&gt;If you enjoy off the wall 70s sci-fi/horror movies, you probably will eat this one up. I was a little dissapointed at how abrubtly it ended. I wanted the movie to keep going, see how things pan out. The DVD revolution has brought so many&lt;br /&gt;&lt;br /&gt;lost clasics back to life, it is truly wonderful. Blue Sunshine is one of those lost &quot;missing links&quot; of the cinema. Enjoy!&#39; | . 2 0.485239 | b&quot;This movie is really really awful. It&#39;s as bad as Zombie 90 well maybe not that bad but pretty close. If your a fan of the Italian horror movies then you might like this movie. I thought that it was dam near unwatchable of course I&#39;m not a fan of the Italian movies. The only Italian movie that was OK was Jungle holocaust. Which is one overrated movie. This film is way overrated. But let&#39;s get started with how horrible this film really is shall we. The acting is goofy and horrible. The effects suck. No plot with this movie. Little gore which is the only good thing in the film isn&#39;t showed nearly enough to be worth watching this wreck. The zombies are very fake looking. It looks like it&#39;s a bunch of dudes wearing cheap dollar store masks. Please avoid this film at all costs.&quot; | . 3 0.251897 | b&#39;Wait a minute... yes I do.&lt;br /&gt;&lt;br /&gt;The director of &#39;The Breed &#39; has obviously seen Terry Gilliam &#39;s &#39;Brazil &#39; a few too many times and asked himself the question, &quot;If &#39;Brazil &#39; had been an ill-conceived tale about vampires in the near future, what would it be like?&quot; Well, I &#39;ll tell ya, it &#39;d be like 91 minutes of a Swedish whore kicking you in the groin, only not as satisfying. The dialogue was laced with gratuitous curse words and trite one-liners, and whoever edited this piece of crap should be shot. I have no real idea of exactly how the whole thing ended because I &#39;m not really sure what happened during the first part of the film. With so many subplots your head begins to hurt and so much bad acting your head wants to explode this movie should only be viewed with large quantities of beer and at least two other people you can MST3K with. The only thing that made me not stab myself in the eye with a dirty soup spoon was this line: Evil Doctor Guy: &quot;That &#39;s it, you are not James Bond, and I am not Blofeld. No more explanations!&quot; Dude From Jason &#39;s Lyric: &quot;I &#39;m getting paid scale!&quot; The cinematography was shaky at best and the acting was putrid. Also, what was with all the pseudo-1984 posters and PA announcements? The costumes were from the 50 &#39;s, the cars were from the 60 &#39;s, the music was from the 90 &#39;s and I wish I were dead. This movie sucks.&#39; | . 4 0.274131 | b&#39;This is the type of movie that &#39;s just barely involving enough for one viewing, but I don &#39;t think I could stand to watch it again. It looks and plays like a mid-Seventies TV movie, only with some gratuitous sex and violence thrown in.&lt;br /&gt;&lt;br /&gt;I agree with several previous posters -- Herve Villechaize is NOT very menacing, and at times even comes off as unintended comedy. At least the other two villains make up for that. Also, it was jolting to see Jonathan Frid is such a pedestrian role, which definitely under-utilized his enormous talents.&lt;br /&gt;&lt;br /&gt;But I think the basic problem with &quot;Seizure&quot; is in the storyline. The evil trio that are conjured up from Frid &#39;s mind are seen too early and too often. They appear to everyone at once, and announce their (murky) plans too early in the picture. In fact, Stone takes this idea and literally shoves it in the viewer &#39;s face, with a series of challenges for the guests; challenges that it doesn &#39;t seem like they have any chance of winning, anyway. How much more effective would have been keeping the evil ones in the shadows, preying on each house guest in turn, sowing confusion and doubt among the remaining house guests, who don &#39;t know who or what is causing the carnage. By having the trio appear early on, to all the &quot;assembled guests&quot;, and announcing their plan (confusing as that plan is), much potential for tension and suspense are lost.&lt;br /&gt;&lt;br /&gt;Also, a more gradual appearance of the evil ones would indicate Frid is slowing losing control of his subconscious. To have Frid subconsciously conjure up these baddies, because he &#39;s got hidden grudges against his wife and friends, would have been a far more logical plot device. Instead of having Frid play an intended victim from the get-go, it would have worked better to have him slowing becoming helpless to control the menace he &#39;s created, with mixed feelings of guilt and satisfaction as his shallow, superficial friends are killed off. The plot Stone offers up is confusing as to the origins and, most importantly, the motivations of the evil trio, and never gives any explanation why Frid, from whose mind they came from, can exercise absolutely no control over them. Confusing is the word that best sums up the whole picture, and the end feels like a total cheat. Better to have some great showdown in which Frid is finally able to banish the creations of his own tormented mind.&lt;br /&gt;&lt;br /&gt;Oliver Stone has done some notable work in his career, but sadly &quot;Seizure&quot; is not among them.&#39; | .",
            "url": "https://dzlab.github.io/notebooks/2020/03/20/Text_classification_with_BERT_and_TF_Text.html",
            "relUrl": "/2020/03/20/Text_classification_with_BERT_and_TF_Text.html",
            "date": " • Mar 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc: true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://dzlab.github.io/notebooks/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://dzlab.github.io/notebooks/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://dzlab.github.io/notebooks/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}